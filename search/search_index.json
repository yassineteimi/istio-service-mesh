{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"1. Intro","text":""},{"location":"#what-is-service-mesh","title":"What is Service Mesh","text":"<p>Ref: https://istio.io/docs/concepts/what-is-istio/#what-is-a-service-mesh</p> <p>Istio Service Mesh is a network connectivity (i.e. mesh) within Kubernetes cluster created by Envoy proxy containers, be it a standalone or a sidecar proxy: </p> <p>Another huge benefit of Istio is the default in-cluster mutual TLS.</p> <p>Without istio, say if using Ingress controller, you can configure TLS termnation at ingress controller pod, like this: </p> <p>With istio, connections among pods in the cluster behind the what-used-to-be ingress controller (i.e. Istio Gateway) can be mutual TLS, without changing app code: </p>"},{"location":"advanced_routing/","title":"Advanced routing","text":""},{"location":"advanced_routing/#traffic-splitting-ie-canary-weight-based-routing-using-virtual-service-subset","title":"Traffic Splitting (i.e. Canary, weight-based routing) using Virtual Service Subset","text":""},{"location":"advanced_routing/#step-1-add-version-label-to-pods","title":"Step 1: Add version label to pods","text":"<pre><code># check pod labels for pod with app=reviews\nkubectl get pod --show-labels --selector app=reviews\n\n# output\nNAME                          READY   STATUS    RESTARTS   AGE   LABELS\nreviews-v1-7f6558b974-wtmj8   2/2     Running   0          23h   app=reviews,istio.io/rev=default,pod-template-hash=7f6558b974,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=reviews,service.istio.io/canonical-revision=v1,version=v1\nreviews-v2-6cb6ccd848-hrpbg   2/2     Running   0          23h   app=reviews,istio.io/rev=default,pod-template-hash=6cb6ccd848,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=reviews,service.istio.io/canonical-revision=v2,version=v2\nreviews-v3-cc56b578-dg7gq     2/2     Running   0          23h   app=reviews,istio.io/rev=default,pod-template-hash=cc56b578,security.istio.io/tlsMode=istio,service.istio.io/canonical-name=reviews,service.istio.io/canonical-revision=v3,version=v3\n</code></pre> <p>Notice three different <code>reviews</code> pods have <code>version=v1</code>, <code>version=v2</code>, and <code>version=v3</code>. These pods are created from three separate deployments.</p> <pre><code>kubectl get deploy --selector app=reviews\n\n# output\nNAME         READY   UP-TO-DATE   AVAILABLE   AGE\nreviews-v1   1/1     1            1           23h\nreviews-v2   1/1     1            1           23h\nreviews-v3   1/1     1            1           23h\n</code></pre> <p>You can also see this on <code>Kiali</code> dashboard <pre><code># open kiali dashboard\nistioctl dashboard kiali\n</code></pre> </p> <p>However, they are proxied by one service using <code>app=reviews</code> label <pre><code># show reviews service and its labels\nkubectl get svc reviews --show-labels\n\n# output\nNAME      TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE   LABELS\nreviews   ClusterIP   10.100.5.108   &lt;none&gt;        9080/TCP   23h   app=reviews,service=reviews\n</code></pre></p> <p></p>"},{"location":"advanced_routing/#step-2-create-istio-destinationrule-resource","title":"Step 2: Create Istio DestinationRule resource","text":"<p>A subset/version of a route destination is identified with a reference to a named service subset which must be declared in a corresponding DestinationRule.</p>"},{"location":"advanced_routing/#destinationrule-anatomy","title":"DestinationRule Anatomy","text":"<p>In destination_rules_versioning.yaml, <pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: DestinationRule\nmetadata:\n  name: reviews\nspec:\n  host: reviews # name of a service from the service registry (in-cluster or could be external)\n  trafficPolicy: # service-level traffic policy\n      loadBalancer:\n        simple: ROUND_ROBIN # default, so you don't need to specify it explicitly\n  subsets: # One or more named sets that represent individual versions of a service. Traffic policies can be overridden at subset level.\n  - name: v1 # &lt;--- named version/subset\n    labels:\n      version: v1 # label attached to Pod definition\n  - name: v2\n    labels:\n      version: v2\n  - name: v3\n    labels:\n      version: v3\n</code></pre></p> <p>Breakdown: - host     - name of a service from the service registry.      - in-cluster service: looked up from Kubernetes services     - external (from K8s) service: looked up from the hosts declared by ServiceEntries - trafficPolicy (more in details in coming sections)     - load balancing policy         - round robin, random, least connection     - connection pool sizes         - controlling the volume of connections to an upstream service     - outlier detection         - controlling eviction of unhealthy hosts from the load balancing pool - subset     - One or more named sets that represent individual versions of a service     - trafficPolicy         - Traffic policies can be overridden at subset level.</p> <p>Apply  <pre><code>kubectl apply -f destination_rules_versioning.yaml\n\n# check\nkubectl get dr\nNAME      HOST      AGE\nreviews   reviews   5s\n</code></pre></p> <p></p>"},{"location":"advanced_routing/#step-3-add-subset-and-weight-to-route-destination-in-virtual-service","title":"Step 3: Add Subset and Weight to route destination in Virtual Service","text":"<p>In virtualservice_reviews_canary.yaml, <pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: reviews\nspec:\n  hosts: # destinations that these routing rules apply to. VirtualService must be bound to the gateway and must have one or more hosts that match the hosts specified in a server\n  - reviews\n  gateways: # names of gateways and sidecars that should apply these routes\n  - bookinfo-gateway # Don't ONLY USE this gateway as \"reviews\" k8s service is used internally by productpage service, so this VS rule should be applied to Envoy sidecar proxy inside reviews pod, not edge proxy in gateway pod. \n  - mesh # applies to all the sidecars in the mesh. The reserved word mesh is used to imply all the sidecars in the mesh. When gateway field is omitted, the default gateway (mesh) will be used, which would apply the rule to all sidecars in the mesh. If a list of gateway names is provided, the rules will apply only to the gateways. To apply the rules to both gateways and sidecars, specify mesh as one of the gateway names. Ref: https://istio.io/latest/docs/reference/config/networking/virtual-service/#VirtualService\n  http: # L7 load balancing by http path and host, just like K8s ingress resource\n  - route:\n    - destination:\n        host: reviews\n        subset: v1\n      weight: 10 # &lt;--- canary release. % of traffic to subset v1\n    - destination:\n        host: reviews\n        subset: v2\n      weight: 10\n    - destination:\n        host: reviews\n        subset: v3\n      weight: 80\n</code></pre></p> <p>Apply  <pre><code>kubectl apply -f virtualservice_reviews_canary.yaml\n\n# check\nkubectl get vs\nNAME      HOST      AGE\nreviews   reviews   5s\n</code></pre></p> <p></p>"},{"location":"advanced_routing/#step-4-test-and-verify-canary-traffic-splitting","title":"Step 4: Test and Verify Canary Traffic Splitting","text":"<p>Go to browser, now you should see 10% of time reviews is v1 (no stars) and v2 (black stars) respectively, and 80% of time v3 (red stars)</p> <pre><code>echo $(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')/productpage\n\n# check this from browser\na5a1acc36239d46038f3dd828465c946-706040707.us-west-2.elb.amazonaws.com/productpage\n\n# or make arbitrary # of requests from curl\nfor i in {1..20}; do curl $(echo $(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')/productpage); done\n</code></pre> <p><pre><code># open kiali dashboard\nistioctl dashboard kiali\n</code></pre> Go to <code>kiali</code> dashboard -&gt; Graph -&gt; select <code>default</code> namespace &gt; select Display dropdown and check off \"Traffic Animation\" </p> <p>Then dashboard will show request percentage </p> <p>You can also see request tracing/metrics from Service &gt; Reviews &gt; Traces </p>"},{"location":"advanced_routing/#identity-based-routing","title":"Identity-Based Routing","text":"<p>Ref: https://istio.io/latest/docs/reference/config/networking/virtual-service/#HTTPMatchRequest</p> <p></p> <p>In virtualservice_reviews_header_condition_identity_based.yaml, <pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: reviews\nspec:\n  hosts: # destinations that these routing rules apply to. VirtualService must be bound to the gateway and must have one or more hosts that match the hosts specified in a server\n  - reviews\n  gateways: # names of gateways and sidecars that should apply these routes\n  - bookinfo-gateway # Don't ONLY USE this gateway as \"reviews\" k8s service is used internally by productpage service, so this VS rule should be applied to Envoy sidecar proxy inside reviews pod, not edge proxy in gateway pod. \n  - mesh # applies to all the sidecars in the mesh. The reserved word mesh is used to imply all the sidecars in the mesh. When gateway field is omitted, the default gateway (mesh) will be used, which would apply the rule to all sidecars in the mesh. If a list of gateway names is provided, the rules will apply only to the gateways. To apply the rules to both gateways and sidecars, specify mesh as one of the gateway names. Ref: https://istio.io/latest/docs/reference/config/networking/virtual-service/#VirtualService\n  http: # L7 load balancing by http path and host, just like K8s ingress resource\n  - match: # &lt;---- this routing to apply to all requests from the specifieduser\n    - headers: # Note: The keys uri, scheme, method, and authority will be ignored.\n        end-user: # WARNING: merely passing this key-value pair in curl won't work as productpage service won't propagate custom header attributes to review service! You need to login as a user Ref: https://stackoverflow.com/a/50878208/1528958\n          exact: log-in-as-this-user\n    route:\n    - destination:\n        host: reviews\n        subset: v1 # then route traffic destined to reviews (defined in hosts above) to backend reviews service of version 1\n  - route:\n    - destination:\n        host: reviews\n        subset: v1\n      weight: 10 # &lt;--- canary release. % of traffic to subset v1\n    - destination:\n        host: reviews\n        subset: v2\n      weight: 10\n    - destination:\n        host: reviews\n        subset: v3\n      weight: 80\n  # - match: # &lt;---- DON'T DO THIS as rules are evaluated in order\n  #   - headers:\n  #       end-user:\n  #         exact: tester\n  #   route:\n  #   - destination:\n  #       host: reviews\n  #       subset: v1\n</code></pre></p> <p>You can add match conditions to http <pre><code>- match:\n   - headers:\n       end-user:\n         exact: tester\n</code></pre></p> <p>Apply <pre><code>kubectl apply -f virtualservice_reviews_header_condition_identity_based.yaml \n</code></pre></p>"},{"location":"advanced_routing/#how-to-test","title":"How to Test","text":""},{"location":"advanced_routing/#warning-passing-custom-header-attributes-using-browser-plugin-or-curl-wont-work-as-productpage-app-wont-propagate-those-attributes-to-reviews-app-usually-these-work-but-not-with-bookinfo-app","title":"Warning: passing custom header attributes using browser plugin or curl won't work, as productpage app won't propagate those attributes to reviews app. Usually these work but not with <code>bookinfo</code> app:","text":""},{"location":"advanced_routing/#wont-work","title":"WON'T WORK:","text":"<p>~~From a browser, install <code>ModHeader</code> chrome plugin so you can modify HTTP header~~ </p> <p>~~And you will see reviews v1, which is just texts without stars.~~ </p> <p>~~From curl, make requests with header attribute~~ <pre><code>for i in {1..20}; do curl --verbose \\\n    --header \"user-agent: tester\" \\\n    $(echo $(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')/productpage); done\n</code></pre></p>"},{"location":"advanced_routing/#works","title":"WORKS:","text":"<p>You login to bookinfo page as an user.</p> <p> </p> <p>Kiali shows traffic is routed to reviews v1 </p>"},{"location":"advanced_routing/#query-string-condition-routing","title":"Query String Condition Routing","text":"<p>In virtualservice_reviews_header_condition_query_string.yaml, <pre><code>  http: # L7 load balancing by http path and host, just like K8s ingress resource\n  - match:\n    - queryParams: # &lt;----- query parameter\n        test-v2:\n          exact: \"true\" # if \"?test-v2=true\" in query string. NOTE: prefix not supported for queryString\n    route:\n    - destination:\n        host: reviews\n        subset: v2 # then route traffic destined to reviews (defined in hosts above) to backend reviews service of version \uff12\n</code></pre></p> <p>Unfortunately, <code>productpage</code> app won't pass along header info including query string parameters to <code>reviews</code> app, so this can't be tested</p>"},{"location":"advanced_routing/#uri-http-path-condition-routing","title":"URI (HTTP path) Condition Routing","text":"<p>In virtualservice_reviews_header_condition_uri.yaml, <pre><code>  http: # L7 load balancing by http path and host, just like K8s ingress resource\n  - match:\n    - uri:\n        regex: '^/productpage/v2' # could be exact|prefix|regex\n      ignoreUriCase: true\n    route:\n    - destination:\n        host: reviews\n        subset: v2 # then route traffic destined to reviews (defined in hosts above) to backend reviews service of version \uff12\n</code></pre></p> <p>Unfortunately, <code>productpage</code> app won't pass along header info including query string parameters to <code>reviews</code> app, so this can't be tested</p>"},{"location":"advanced_routing/#inject-latency-delay-for-resilience-testing-using-virtualservice","title":"Inject Latency Delay for Resilience Testing using VirtualService","text":"<p>Refs:  - https://istio.io/latest/docs/reference/config/networking/virtual-service/#HTTPFaultInjection-Delay - https://istio.io/latest/docs/concepts/traffic-management/#fault-injection</p> <p></p> <p>Delays: Delays are timing failures. They mimic increased network latency or an overloaded upstream service</p> <p>In virtualservice_ratings_fault_injection_delay.yaml, <pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: ratings\nspec:\n  hosts: # destinations that these routing rules apply to. VirtualService must be bound to the gateway and must have one or more hosts that match the hosts specified in a server\n  - ratings\n  http: # L7 load balancing by http path and host, just like K8s ingress resource\n  - match:\n    - headers: # Note: The keys uri, scheme, method, and authority will be ignored.\n        end-user: # WARNING: merely passing this key-value pair in curl won't work as productpage service won't propagate custom header attributes to review service! You need to login as a user Ref: https://stackoverflow.com/a/50878208/1528958\n          exact: tester\n    fault: \n      delay: # &lt;------ inject latency \n        percentage:\n          value: 100.0 # Percentage number in the range of [0.0, 100.0]. Ref: https://istio.io/latest/docs/reference/config/networking/virtual-service/#Percent\n        fixedDelay: 10s # &lt;----- delay\n    route:\n    - destination:\n        host: ratings\n        subset: v1\n  - route:\n    - destination:\n        host: ratings\n        subset: v1\n</code></pre></p> <p>Apply  <pre><code>kubectl apply -f virtualservice_ratings_fault_injection_delay.yaml\n</code></pre></p> <p>Login as <code>tester</code> and access it from browser.</p> <p>You expect the Bookinfo home page to load without errors in approximately 7-10 seconds. However, the Reviews section displays an error message: <code>Sorry, product reviews are currently unavailable for this book.</code> </p> <p>This was the result of <code>productpage</code> receiving the timeout error from the <code>reviews</code> service, which couldn't get a response from <code>ratings</code> service which has 10s delay within <code>productpage</code> timeout (default application-level timeout of 3s times 1 retry = 7s).</p> <pre><code>productpage -&gt; (3s timeout x 1 retry = max 6s) -&gt; reviews -&gt; ratings with 10s delay\n</code></pre> <p></p> <p>You can also check the delay from Developer Tools menu &gt; Network tab &gt; Reload the /productpage web page, and you see 7s latency: </p> <p>From Kiali </p>"},{"location":"advanced_routing/#why-7-second-latency-despite-10s-delay","title":"Why 7 second latency despite 10s delay?","text":"<p>Ref: https://istio.io/latest/docs/tasks/traffic-management/fault-injection/#understanding-what-happened</p> <p>Timeout between the <code>reviews</code> and <code>ratings</code> service is hard-coded at 10s. However, there is also a hard-coded timeout between the <code>productpage</code> and the <code>reviews</code> service, coded as 3s + 1 retry for 6s total. As a result, the productpage call to reviews times out prematurely and throws an error after 6s.</p>"},{"location":"advanced_routing/#mirror-live-traffic-using-virtualservice","title":"Mirror Live Traffic using VirtualService","text":"<p>Refs: - https://istio.io/latest/docs/tasks/traffic-management/mirroring/ - https://istio.io/latest/docs/reference/config/networking/virtual-service/#HTTPRoute</p> <p></p> <p>Mirroring sends a copy of live traffic to a mirrored service.</p> <p>When traffic gets mirrored, the requests are sent to the mirrored service with their Host/Authority headers appended with -shadow. For example, cluster-1 becomes cluster-1-shadow.</p> <p>In virtualservice_reviews_mirror.yaml, <pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: reviews\nspec:\n  hosts: # destinations that these routing rules apply to. VirtualService must be bound to the gateway and must have one or more hosts that match the hosts specified in a server\n  - reviews\n  gateways: # names of gateways and sidecars that should apply these routes\n  - bookinfo-gateway # Don't ONLY USE this gateway as \"reviews\" k8s service is used internally by productpage service, so this VS rule should be applied to Envoy sidecar proxy inside reviews pod, not edge proxy in gateway pod. \n  - mesh # applies to all the sidecars in the mesh. The reserved word mesh is used to imply all the sidecars in the mesh. When gateway field is omitted, the default gateway (mesh) will be used, which would apply the rule to all sidecars in the mesh. If a list of gateway names is provided, the rules will apply only to the gateways. To apply the rules to both gateways and sidecars, specify mesh as one of the gateway names. Ref: https://istio.io/latest/docs/reference/config/networking/virtual-service/#VirtualService\n  http: # L7 load balancing by http path and host, just like K8s ingress resource\n  - mirror: # &lt;---- mirror traffic going to v3 to v1 as well, 100% of it\n      host: reviews\n      subset: v1\n    mirror_percent: 100.0 # use double. https://istio.io/latest/docs/reference/config/networking/virtual-service/#HTTPRoute\n    route:\n    - destination:\n        host: reviews\n        subset: v3\n      weight: 100\n</code></pre></p> <p>Apply <pre><code># apply normal ratings virtual service without delay nor abort\nkubectl apply -f virtualservice_ratings.yaml \n\nkubectl apply -f virtualservice_reviews_mirror.yaml \n</code></pre></p> <p>Visit the URL from browser</p> <p>You can see traffic to v3: </p> <p>v1 is mirroring the traffic: </p> <p>And v1's istio proxy log shows header host is appended with <code>-shadow</code> as in <code>reviews-shadow</code> </p> <p>However, v2 isn't receiving any traffic. </p>"},{"location":"advanced_routing/#return-arbitrary-http-response-for-resilience-testing-using-virtualservice","title":"Return Arbitrary HTTP Response for Resilience Testing using VirtualService","text":"<p>Refs:  - https://istio.io/latest/docs/reference/config/networking/virtual-service/#HTTPFaultInjection-Abort - https://istio.io/latest/docs/concepts/traffic-management/#fault-injection</p> <p></p> <p>Aborts: Aborts are crash failures. They mimic failures in upstream services. Aborts usually manifest in the form of HTTP error codes or TCP connection failures.</p> <p>In virtualservice_ratings_fault_injection_abort.yaml, <pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: ratings\nspec:\n  hosts: # destinations that these routing rules apply to. VirtualService must be bound to the gateway and must have one or more hosts that match the hosts specified in a server\n  - ratings\n  http: # L7 load balancing by http path and host, just like K8s ingress resource\n  - match:\n    - headers: # Note: The keys uri, scheme, method, and authority will be ignored.\n        end-user: # WARNING: merely passing this key-value pair in curl won't work as productpage service won't propagate custom header attributes to review service! You need to login as a user Ref: https://stackoverflow.com/a/50878208/1528958\n          exact: tester\n    fault: \n      abort: # &lt;----- return pre-specified HTTP code\n        percentage:\n          value: 100.0 # Percentage number in the range of [0.0, 100.0]. Ref: https://istio.io/latest/docs/reference/config/networking/virtual-service/#Percent\n        httpStatus: 400\n    route:\n    - destination:\n        host: ratings\n        subset: v1\n  - route:\n    - destination:\n        host: ratings\n        subset: v1\n</code></pre></p> <p>Apply  <pre><code>kubectl apply -f virtualservice_ratings_fault_injection_abort.yaml\n</code></pre></p> <p>Login as <code>tester</code> and access it from browser, the page loads immediately, as opposed to 7s delay like previous section, and the Ratings service is currently unavailable message appears.  </p> <p>Now you see red line from <code>reviews</code> pod to <code>ratings</code> service in Kiali. </p>"},{"location":"advanced_routing/#configure-load-balancing-policy-using-destination-rule","title":"Configure Load Balancing Policy using Destination Rule","text":"<p>Refs: - https://istio.io/latest/docs/concepts/traffic-management/#destination-rule-example - https://istio.io/latest/docs/reference/config/networking/destination-rule/</p> <p></p> <p>Destination Rule defines policies that apply to traffic intended for a service after routing has occurred</p> <p>Destination Rule can configure: - load balancing algorithm (random, least connection, round robin) - connection pool size from the sidecar - outlier detection settings to detect and evict unhealthy hosts from the load balancing pool</p> <p>Without Istio DestinationRule's Traffic Policy, by default you are left with K8s service's L4 load balancing (round robin by default).</p> <p>With Istio DestinationRule's Traffic Policy, you could control and split traffic to subset/versioned pods, and among those pods you can configure fine-graied LB algorithms such as round robin, random, least-connection, sticky sessions, etc</p>"},{"location":"advanced_routing/#round-robin-load-balancing-default","title":"Round Robin Load Balancing (default)","text":"<pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: DestinationRule\nmetadata:\n  name: reviews\nspec:\n  host: reviews # name of a service from the service registry\n#   trafficPolicy: # service-level routing policy\n#       loadBalancer:\n#         simple: ROUND_ROBIN # default, so you don't need to specify it explicitly\n</code></pre>"},{"location":"advanced_routing/#random-load-balancing","title":"Random Load Balancing","text":"<p>It selects a random healthy host. The random load balancer generally performs better than round robin if no health checking policy is configured.</p> <pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: DestinationRule\nmetadata:\n  name: reviews\nspec:\n  host: reviews\n  trafficPolicy: # service-level routing policy\n      loadBalancer:\n        simple: RANDOM # selects a random healthy host\n</code></pre>"},{"location":"advanced_routing/#least-request-load-balancing","title":"Least request load balancing","text":"<p>This uses an O(1) algorithm which selects two random healthy hosts and picks the host which has fewer active requests. <pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: DestinationRule\nmetadata:\n  name: reviews\nspec:\n  host: reviews\n  trafficPolicy: # service-level routing policy\n      loadBalancer:\n        simple: LEAST_CONN # selects two random healthy hosts and picks the host which has fewer active requests\n</code></pre></p>"},{"location":"advanced_routing/#multiple-load-balancing-rules-for-subsets","title":"Multiple Load Balancing Rules for Subsets","text":"<p>In this example, we define: - service-level trafficPolicy for <code>loadBalancer</code> and specify <code>ROUND_ROBIN</code> - version specific trafficPolicy for <code>loadBalancer</code> and specify <code>LEAST_CONN</code> for subset <code>v1</code> - <code>RANDOM</code> for subset <code>v2</code> <pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: DestinationRule\nmetadata:\n  name: reviews\nspec:\n  host: reviews # name of a service from the service registry (in-cluster or could be external)\n  trafficPolicy: # service-level traffic policy\n    loadBalancer:\n      simple: ROUND_ROBIN # default, so you don't need to specify it explicitly\n  subsets: # One or more named sets that represent individual versions of a service. Traffic policies can be overridden at subset level.\n  - name: v1\n    labels:\n      version: v1 # label attached to Pod definition\n    trafficPolicy: # Version specific policies, which overrides service-level traffic \n      loadBalancer:\n        simple: LEAST_CONN\n  - name: v2\n    labels:\n      version: v2\n    trafficPolicy: # Version specific policies, which overrides service-level traffic policy\n      loadBalancer:\n        simple: RANDOM\n</code></pre></p>"},{"location":"advanced_routing/#enable-sticky-session-for-load-balancing-in-destinationrule","title":"Enable Sticky Session for Load Balancing in DestinationRule","text":"<pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: DestinationRule\nmetadata:\n  name: reviews\nspec:\n  host: reviews # name of a service from the service registry\n  trafficPolicy: # service-level routing policy\n    loadBalancer:\n        consistentHash: # &lt;--- changed from \"simple\"\n            httpCookie:\n                name: user # Name of the cookie.\n                ttl: 1800s # Lifetime of the cookie\n</code></pre>"},{"location":"before_istio/","title":"Things to know","text":""},{"location":"before_istio/#keys-differences-between-istio-on-kubernetes-vs-istio-on-redhat-openshift","title":"Keys differences between istio on Kubernetes vs istio on redhat Openshift","text":""},{"location":"before_istio/#difference-1-istio-installation","title":"Difference #1: istio installation","text":"<p>To run istio service mesh on :</p> <ul> <li>Openshift you must use the redhat istio service mesh operator among other operators. (see mesh installation page for more details).</li> <li>kubernetes (see mesh installation page for more details).</li> </ul> <p>Red Hat OpenShift Service Mesh does not support Istio installation profiles.</p> <p>Red Hat OpenShift Service Mesh does not support canary upgrades of the service mesh.</p>"},{"location":"before_istio/#difference-2-enabling-sidecar-autoinjection","title":"Difference #2: Enabling sideCar autoInjection","text":"<p>Red Hat OpenShift Service Mesh does not automatically inject the sidecar into any pods, but you must opt in to injection using an annotation without labeling projects.</p> <p>The upstream Istio community installation automatically injects the sidecar into pods within the projects you have labeled.</p>"},{"location":"before_istio/#difference-3-redhat-operator-specific-objects","title":"Difference #3: Redhat operator specific objects","text":"<p>The Redhat operator adds a bundle of objects : SMCP, SMMR.</p> <ul> <li>SMCP is the service mesh control plane.</li> <li>SMMR is the service mesh member role, the way to include a project in the service mesh.</li> </ul>"},{"location":"before_istio/#difference-4-command-line-tool","title":"Difference #4 : Command line tool","text":"<p>The command line tool for Red Hat OpenShift Service Mesh is <code>oc</code> Red Hat OpenShift Service Mesh does not support <code>istioctl</code></p>"},{"location":"before_istio/#redhat-support","title":"Redhat support","text":""},{"location":"before_istio/#istio-service-mesh-operator-support","title":"Istio service mesh operator support","text":"<p>The Red Hat OpenShift Service Mesh Operator supports multiple versions of the ServiceMeshControlPlane resource.</p> <p>Version 2.2 Service Mesh control planes are supported on the following platform versions:</p> <ul> <li>Red Hat OpenShift Container Platform version 4.9 or later.</li> <li>Red Hat OpenShift Dedicated version 4.</li> <li>Azure Red Hat OpenShift (ARO) version 4.</li> <li>Red Hat OpenShift Service on AWS (ROSA).</li> </ul>"},{"location":"before_istio/#supported-configurations-for-kiali","title":"Supported configurations for Kiali","text":"<p>The Kiali console is only supported on the two most recent releases of the Chrome, Edge, Firefox, or Safari browsers.</p>"},{"location":"before_istio/#supported-configurations-for-distributed-tracing","title":"Supported configurations for Distributed Tracing","text":"<p>Jaeger agent as a sidecar is the only supported configuration for Jaeger. Jaeger as a daemonset is not supported for multitenant installations or OpenShift Dedicated.</p>"},{"location":"before_istio/#about-the-operator","title":"About the operator","text":"<p>To check the operator official github repo, please click here</p>"},{"location":"before_istio/#redhat-istio-operator-known-issues","title":"RedHat Istio Operator Known issues","text":"<p>When you uninstall the operators, custom resources hang out, and persist:</p> <ul> <li>Original issue here</li> <li>Similar issue 1 with solution here</li> <li>Similar issue 2 with solution here</li> </ul> <p>This issue costs me countless hours of debugging, please read it carefully before uninstalling your servicemesh operators on Openshift. Basically you should look for the CRD finalizer and delete it, in order to get rid of the CRD.</p>"},{"location":"before_istio/#general-pre-requisites","title":"General Pre-requisites","text":"<ul> <li> <p>Before getting your hands dirty, you should be aware of the Redhat servicemesh architecture and design patterns. (Network communicaion level, Data and control plan work, Istio components, Istio ingress, network policies created, ...) Please read carefully the istio service mesh introduction + design patterns considerations.</p> </li> <li> <p>Access right management: Managing users and profiles (access to service mesh by a group of users [teams, department, ...], ...)</p> </li> <li> <p>Security decisions/strategy:</p> <ul> <li>Define a TLS version (if required by the organization policy for example).</li> <li>TLS mode upgrade stategy: Use permissive mode while you migrate your workloads to Service Mesh. Then, you can enable strict mTLS across your mesh, namespace, or application.</li> </ul> </li> </ul>"},{"location":"before_istio/#certificate-management-with-istio-mtls","title":"Certificate management with Istio mTLS","text":"<p>The Citadel component in Istio manages the lifecycle of keys and certificates issued for services. When Istio establishes mutual TLS authentication, it uses these keys and certificates to exchange the identities of services.</p> <p>To establish a mutual TLS connection between two services, the envoy proxy on the client side establishes a mutual TLS handshake with the envoy proxy on the server side during which the client side envoy proxy verifies the identity of the server side and whether it is authorized to run the target service.</p> <p>When the identities of the services are verified, the mutual TLS connection is established and the client service sends communication through the client side proxy to the server side proxy and finally to the target service.</p> <p>The authentication policies and secure naming information is distributed to the Envoy proxies by the Pilot component. The Mixer component handles the authorization and auditing part of Istio security.</p>"},{"location":"before_istio/#setting-the-correct-network-policy","title":"Setting the correct network policy","text":"<p>Service Mesh creates network policies in the Service Mesh control plane and member namespaces to allow traffic between them. Before you deploy, consider the following conditions to ensure the services in your service mesh that were previously exposed through an OpenShift Container Platform route:</p> <ul> <li> <p>Traffic into the service mesh must always go through the ingress-gateway for Istio to work properly.</p> </li> <li> <p>Deploy services external to the service mesh in separate namespaces that are not in any service mesh.</p> </li> <li> <p>Non-mesh services that need to be deployed within a service mesh enlisted namespace should label their deployments maistra.io/expose-route: \"true\", which ensures OpenShift Container Platform routes to these services still work.</p> </li> </ul>"},{"location":"before_istio/#references","title":"References","text":"<p>Service Mesh documentation</p>"},{"location":"design_considerations/","title":"Design considerations at the edge of the servicemesh","text":"<p>In my experience of implementing Red Hat ServiceMesh, I found that the mesh behaves like a special zone within an enterprise network. Inside of it, configurations are clear and strictly enforced. We have no control on what is outside of it, and we should assume that there can be anything.</p> <p>Perhaps unexpectedly, we noticed that most of the time was spent around designing the edge of the mesh. The edge of the mesh is where coexistence with the external world needs to be configured.</p>"},{"location":"design_considerations/#general-considerations-on-inbound-and-outbound-traffic","title":"General Considerations on Inbound and Outbound Traffic","text":"<p>To better understand the next paragraphs, it\u2019s useful to recall how traffic routing decisions are made in Istio (the model that we are about to present works well for HTTP traffic). Consider the following diagram:</p> <p></p> <p>Moving from the left to the right:</p> <ol> <li>When a connection hits a member of the mesh (let\u2019s imagine an ingress gateway, but it works the same for every member), all the routing decisions are made based on the hostname (host header field).</li> <li>Ingress gateways are configured to listen for connections on certain ports and for certain hostnames based on Gateway objects. A gateway configuration selects the gateway pods to which it\u2019s applied based on a label selector. Gateway objects should be defined in the same namespace where the gateway pods reside.</li> <li>By default, ingress gateways are not aware of the services in the mesh. To make an ingress gateway aware of a service in the mesh, a VirtualService must be defined and applied to the gateway object. When the VirtualService is not in the same namespace as the gateway object, which should be the case in most situations, the gateway object should be referenced in NamespacedName format (\"namespace\"/\"gateway\").</li> <li>A VirtualService may be coupled with a DestinationRule for fine-grained traffic management.</li> <li>A VirtualService will then route to an active member of a Kubernetes service (auto discovered) or to a ServiceEntry. ServiceEntries (here is an example) provide the ability to manually define endpoints that cannot be auto-discovered and may represent destinations outside of the mesh (location: MESH_EXTERNAL).</li> </ol>"},{"location":"design_considerations/#designing-ingress-traffic","title":"Designing Ingress Traffic","text":"<p>For inbound traffic, it\u2019s generally a good practice to drive traffic through one or more ingress gateways before letting it hit the services.</p> <p>When designing how to deploy the ingress gateways of a service mesh, two main considerations are needed:</p> <ol> <li>How many ingress gateways are needed?</li> <li>What is the relationship between the ingress gateways and OpenShift routers?</li> </ol> <p>First consideration: One ingress gateway per mesh (OpenShift ServiceMesh supports multiple service meshes deployed in a single OpenShift instance) should be enough in most cases.</p> <p>However, you might have scenarios in which additional gateways are needed. Scenarios include when two radically different configurations need to be supported or when two kinds of traffic need to be kept physically separated (here is an example of this configuration). Another instance when you might have more than one ingress gateway is when ingress gateways need to be owned by individual tenants within their namespace.</p> <p>The below diagram captures three ingress gateway deployment patterns:</p> <p></p> <p>The last configuration setup is not currently supported by the OpenShift Service Mesh operator and requires manual setup by tenants.</p> <p>The other important decision is whether to expose the ingress gateway mediated by an OpenShift router or directly exposed to external traffic via LoadBalancer service.</p> <p></p> <p>In this diagram, we can see two scenarios, one with the OpenShift router an ingress gateway chained together and one with the ingress gateway directly exposed.</p> <p>Conceptually, the router is the entry point for traffic to enter into the OpenShift SDN and the Service Mesh ingress gateway is for traffic to enter into the mesh. The chaining of both the router and ingress gateway may introduce too many hops and may add latency to service calls.</p> <ul> <li>Scenario 1: more appropriate when the traffic is HTTP(s) or SNI+TLS, as this is the type of traffic supported by the router and when the added latency is not an issue.</li> <li>Scenario 2: more appropriate in situations where the traffic is of a type not supported natively by the router or it\u2019s important to have good latency performance. In these scenarios, the mesh administrator needs to configure the LoadBalancer service along with the proper DNS records.</li> </ul>"},{"location":"design_considerations/#enforcing-ingress-traffic","title":"Enforcing Ingress Traffic","text":"<p>The above considerations help to design the shape of our ingress traffic, but we might also want to enforce that the ingress pathways we have created are the only form of allowable traffic.</p> <p>NetworkPolicy is the right tool for the job at hand (a good, but not 100% accurate, mental model is to think of NetworkPolicies as ways to enforce traffic rules at layer 4 and Istio configurations as ways of enforcing traffic rules at layer 7).</p> <p>There does not seem to be a way to configure the service mesh control plane to disallow traffic from the router (Feature request: https://github.com/maistra/istio/issues/127).</p> <p>We can still enforce that traffic only originates from the Service Mesh by removing the permission to create routes via RBAC. We will also need to make sure that tenants cannot change the created network policies (again via RBAC).</p>"},{"location":"design_considerations/#designing-egress-traffic","title":"Designing Egress Traffic","text":"<p>For egress traffic, we, again, have to decide how many egress gateways we need. In some cases, the answer could be zero. However, in most cases, having one egress gateway will be useful:</p> <p></p> <p>Outbound traffic from a pod in the mesh always traverses through the envoy gateway, so there is a level of control on that traffic, even if it doesn\u2019t flow through an egress gateway.</p> <p>However, egress gateways can be used to achieve the following:</p> <ul> <li>TLS origination : We can use the egress gateway to terminate the TLS connections from the service mesh internal PKI and initiate new connections using the certificate from the external PKI. This allows for two PKI domains to coexist.</li> <li>Using a known egress IP : If outbound connections from services in a mesh need to originate from a known IP so that firewall rules can be applied, an option is to have all outbound connections diverted to an egress gateway and then to define an egress IP on the namespace where the egress-gateway is defined.</li> <li>Organization might have requirements by which all outbound traffic needs to originate from a specific set of nodes.</li> </ul>"},{"location":"design_considerations/#enforcing-egress-traffic","title":"Enforcing Egress Traffic","text":"<p>EgressNetworkPolicies: enforce that no traffic leaves the cluster except from the namespace where the egress gateways are deployed.</p> <p>We can also enforce that traffic leaving the mesh pods stays in the mesh using network policies with egress rules (again, we need to guarantee that the users cannot manage network policies).</p> <p>Additionally, Istio can be configured to forbid the routing of addresses unknown to the mesh.</p> <p>Normally, if an application attempts to open a connection to an address that is unknown to the mesh, Istio would use DNS to resolve the address and execute the request. With the global.outboundTrafficPolicy mode option set to REGISTRY_ONLY, we can configure Istio to only allow connections to known addresses (that is, addresses for which a VirtualService is defined).</p>"},{"location":"design_considerations/#configuring-rate-limiting-for-edge-trafficcircuit-breaker","title":"Configuring Rate Limiting for Edge Traffic/Circuit breaker","text":"<p>In certain scenarios, it might be necessary to rate limit the outbound traffic from the mesh. These types of traffic controls are useful when an upstream service may have imposed limits based on pricing tier, or legacy systems that may only be able to handle a certain amount of requests or concurrent connections over a period of time.</p> <p>Furthermore, different SLAs might be applied for traffic originating from different sources and creating a need to rate limit these traffic types in different ways.</p> <p>Destination rules and traffic policies can be used in conjunction with circuit breakers to manage how inbound requests of different SLAs can be prioritized when propagating out of the mesh.</p> <p></p> <p>In the above diagram, we demonstrate how two different inbound requests that are assigned different SLA classes (one such way can be assigning a header) can be used to apply different destination rules and corresponding traffic policies (here is an example). These methods can be used to maintain a healthy upstream system and allow for the services in the mesh to continue functioning or apply circuit breakers patterns when the limits are reached.</p>"},{"location":"istio_architecture/","title":"1. Istio Architecture","text":""},{"location":"istio_architecture/#istio-service-mesh-architecture","title":"Istio Service Mesh Architecture","text":"<p>Ref: https://istio.io/latest/docs/ops/deployment/architecture/</p>"},{"location":"istio_architecture/#brief-architectural-summary-of-istio","title":"Brief Architectural Summary of Istio","text":"<ul> <li>service-mesh implementations comes with a control plane(istiod) and a data plane(a standalone edge Envoy proxy and sidecar Envoy proxies)</li> <li>data plane is composed of a set of intelligent proxies (Envoy) deployed as sidecars.  These proxies mediate and control all network communication between microservices. They also collect and report telemetry on all mesh traffic.</li> <li>control plane lives outside of the request path and is used to administer and control the behavior of the data plane</li> </ul>"},{"location":"istio_architecture/#data-plane","title":"Data plane","text":"<ul> <li>Envoy proxy: a high-performance proxy developed in C++ to mediate all inbound and outbound traffic for all services in the service mesh. Envoy proxies are the only Istio components that interact with data plane traffic.</li> <li>Traffic control <ul> <li>a different load balancing policy to traffic for a particular subset of service instances</li> <li>Staged rollouts with %-based traffic split</li> <li>HTTP/2 and gRPC proxies</li> <li>Istio Resources<ul> <li>Virtual services</li> <li>Destination rules</li> <li>Gateways</li> <li>Service entries</li> <li>Sidecars</li> </ul> </li> </ul> </li> <li>Network resiliency<ul> <li>Fault injection</li> <li>Retries</li> <li>Circuit breakers</li> <li>Failovers</li> <li>Health checks</li> </ul> </li> <li>Security and Authentication<ul> <li>Rate limiting</li> <li>TLS termination</li> </ul> </li> </ul>"},{"location":"istio_architecture/#control-plane","title":"Control Plane","text":"<ul> <li>Istiod (consists of pilot, galley, and citadel)<ul> <li>Dynamic service discovery: in order to direct traffic within your mesh, Istio needs to know where all your endpoints are</li> <li>Strong service-to-service and end-user authentication with built-in identity and credential management</li> <li>Pilot - the core data-plane config (xDS) server</li> <li>Galley - configuration watching, validation, forwarding</li> <li>Citadel - certificate signing, secret generation, integration with CAs, etc</li> <li>Telemetry - a \u201cmixer\u201d component responsible for aggregating and syndicating telemetry to various backends</li> <li>Policy - a request-path \u201cmixer\u201d component responsible for enforcing policy</li> </ul> </li> </ul>"},{"location":"istio_architecture/#architecture-change-from-before-and-after-v15","title":"Architecture change from before and after v1.5","text":""},{"location":"istio_architecture/#before-istio-15","title":"Before Istio 1.5","text":""},{"location":"istio_architecture/#after-istio-15","title":"After Istio 1.5","text":"<p>Reduced installation and configuration complexity by moving control plane components into a single component: Istiod. This binary includes the features of Pilot, Citadel, Galley, and the sidecar injector (microservices turned into a monolith in favor of easier management)</p> <p></p>"},{"location":"mesh_debug/","title":"Debug your mesh","text":"<p>Generate traffic:</p> <p>watch -n 1 curl -o /dev/null -s -w %{http_code} http://$GATEWAY_URL</p> <p>Getting Envoy Proxy config:</p> <p>oc exec  -c istio-proxy -- curl -kv localhost:15000/config_dump&gt; _Envoy_config.json <p>Increase the logging level of the Envoy proxy:</p> <p>For a specific component:</p> <p>oc exec -it  -c istio-proxy -- sh -c 'curl -k -X POST localhost:15000/logging?rbac=debug' <p>Example: oc exec -it keycloak-v1-app-0 -c istio-proxy -- sh -c 'curl -k -X POST localhost:15000/logging?rbac=debug?admin=debug?config=debug?router=debug?runtime=debug'</p> <p>Control plane: oc exec -it dispatch-wip-6d6975b7cb-rzxhw -c istio-proxy -- sh -c 'curl -k -X POST localhost:15000/logging?rbac=debug?admin=debug?'</p> <p>Ingress gateway:</p> <p>oc exec -it istio-ingressgateway-77479549b4-kc22p -c istio-proxy -- sh -c 'curl -k -X POST localhost:15000/logging?rbac=debug?admin=debug?config=warning?router=debug?runtime=warning'</p> <p>For all Components:</p> <p>BEWARE! the logs will come too heavy!</p> <p>oc exec -it keycloak-v1-app-0 -c istio-proxy -- sh -c 'curl -k -X POST localhost:15000/logging?level=warning'</p> <p>oc exec -it keycloak-v1-db-postgresql-0 -c istio-proxy -- sh -c 'curl -k -X POST localhost:15000/logging?level=warning'</p> <p>active loggers:   admin: debug   aws: debug   assert: debug   backtrace: debug   client: debug   config: debug   ...   pool: debug   rbac: debug   redis: debug   router: debug   runtime: debug   stats: debug   secret: debug   tap: debug   testing: debug   thrift: debug   tracing: debug   upstream: debug   udp: debug   wasm: debug</p> <p>Port-forwarding:</p> <p>oc port-forward keycloak-v1-db-postgresql-0 15432:5432 psql -h localhost -p 15432 -U admin -d aidc_v1 (sudo apt-install postgresql-client)</p> <p>Sniff postgresql traffic: sudo tcpdump -A -i any port 15432</p> <p>Connecting to Istio Pilot GUI: oc port-forward istio-pilot-775d8bfc6b-zb25d 9876 If we open this website http://localhost:9876/scopez/ in our browser, we see the following GUI:</p> <p>You can do this also for : Mixer, Pilot, Citadel, and Galley oc port-forward  9876 <p>Istio version: oc rsh -n openshift-operators istio-operator-85787fd5f5-kvjfz env | grep ISTIO_VERSION ISTIO_VERSION=1.12.9</p>"},{"location":"mesh_edge_security/","title":"TLS/HTTPS at the edge of the mesh","text":""},{"location":"mesh_edge_security/#configuring-tls-and-mtls-for-edge-traffic","title":"Configuring TLS and mTLS for Edge Traffic","text":"<p>Ingress and egress gateways can be useful to configure how TLS connections should be handled between different PKI trust domains. Istio manages its own PKI by default with an internal trust domain and it is safe to assume that outside of the mesh there are other trust domains.</p> <p>The following is a diagram capturing this scenario:</p> <p></p> <p>In the diagram above, we can see that the application consuming the service within the service mesh is in the trust domain A. In this case, mTLS has been configured between the consumer and the ingress gateway (here are instructions on how this is accomplished). Then, the application makes an outbound call to an external service, which belongs to trust domain B. mTLS is configured by deploying the correct certificates on the egress gateway (here are instructions on this portion).</p> <p>By managing the certificates at the gateway level, we achieve the following:</p> <ul> <li>Easier configuration: There is not an easy way to deploy an additional certificate to a sidecar, but it is relatively easy to add certificate material to the gateways.</li> <li>Centralized configuration: The certificate configuration can be reused by all the services in the mesh.</li> </ul> <p>Naturally, we could have set up a normal TLS deployment by deploying CA bundles instead of client certs, this decision does not impact the service mesh tenants.</p> <p>These kinds of setups are highly simplified if there is a mechanism to automatically provision certificates. The Cert-manager operator is an ideal option in this space.</p>"},{"location":"mesh_installation/","title":"Istio service mesh installation","text":""},{"location":"mesh_installation/#using-redhat-istio-service-mesh-operator-on-openshift","title":"Using RedHat Istio service mesh operator on Openshift","text":""},{"location":"mesh_installation/#installing-operators","title":"Installing operators","text":"<p>You must install all operators from redhat, otherwise, there is no redhat support, and it will install an old Istio version without you KNOWING IT (for me it was v1.4.11), and the latest version is at the time writing this : 1.12.</p> <p>Install the following operators in this in order:</p> <ol> <li>ElasticSearch (from Redhat)    Update channel: stable.    Installation mode: default.    (namespace: openshift-operators-redhat).    Update approval: automatic.</li> <li>Jaeger - Red Hat OpenShift distributed tracing platform (from redhat)    Installation mode: default.    (namespace: openshift-distributed-tracing).    Update approval: automatic.</li> <li>Kiali (from redhat).    Update channel: stable.    Installation mode: default.    (namespace: openshift-operators).    Update approval: automatic.</li> <li>Redhat service mesh operator. (redhat)    Update channel: stable.    Installation mode: default.    (namespace: openshift-operators).    Update approval: automatic.</li> </ol> <p>You can choose between automatic and manual update approval. (automatic for demo purposes)</p> <p>Variable setting: <pre><code># namespace to add into the service mesh\n$ export OCP_NS=myservicemesh-namespace\n</code></pre></p> <p>Check that the operators involved in the Service Mesh installation are installed properly:</p> <pre><code>$ oc get subscription -n openshift-operators\n</code></pre> <p>Check the installation with the ClusterServiceVersion custom resource:</p> <pre><code>$ oc get ClusterServiceVersion\n</code></pre> <p>Create a namespace called istio-system where the Service Mesh control plane will be installed:</p> <pre><code>cd Istio\ncat servicemesh-namespace.yml\n$ oc apply -f servicemesh-namespace.yml\n</code></pre> <p>Create a service mesh controle plane and service member roll in the istio-system namespace and add your namespace into the istio control plane:</p> <pre><code>cat istio/basic-istio-install.yml | NAMESPACE=$OCP_NS envsubst | oc apply -f -\n</code></pre> <p>Run the following command to verify the ServiceMeshContolPlane &amp; ServiceMeshMemberRoll was created successfully:</p> <pre><code>oc get smmr -n istio-system default\nwatch -n 0.2 oc get smcp -n istio-system basic\n#it will take few minutes\n</code></pre>"},{"location":"mesh_installation/#adding-workloads-into-the-mesh","title":"Adding workloads into the mesh","text":"<pre><code>$ oc edit smmr -n &lt;controlplane-namespace&gt;\n</code></pre> <p>Modify the SMMR YAML to add or remove projects as members. You can add any number of projects, but a project can only belong to one ServiceMeshMemberRoll resource.</p>"},{"location":"mesh_installation/#enabling-sidecar-autoinjection","title":"Enabling sideCar autoInjection","text":"<p>SideCar autoInjection can be enabled using annotation at the your application deployment level:</p> <p>First of all, let's check our deployment annotations:</p> <pre><code>$ oc get deployment -n my-deployment -o yaml\n</code></pre> <p>You must add the following annotation <code>sidecar.istio.io/inject: 'true'</code> fllowing this path: <code>spec &gt; template &gt; metadata &gt; annotations</code>.</p> <pre><code># example:\nannotations: sidecar.istio.io/inject: 'true'\n</code></pre> <p>You can do it at the statefulset level also, it's not recommended at the pod level (because of versatility).</p>"},{"location":"mesh_installation/#using-istio-upstream-k8s","title":"Using Istio upstream (K8s)","text":""},{"location":"mesh_installation/#install-istio-using-istioctl","title":"Install Istio using istioctl","text":"<pre><code># first install istioctl CLI\ncurl -L https://istio.io/downloadIstio | ISTIO_VERSION=1.6.6 sh -\ncd istio-1.6.6\necho \"export PATH=$PWD/bin:$PATH\" &gt;&gt; ~/.bash_profile\n\n# open new shell to load updated PATH variable\n</code></pre>"},{"location":"mesh_installation/#install-istio-to-k8s-cluster-using-istio-config-profile","title":"Install Istio to K8s cluster using istio config profile","text":"<p>Ref: https://istio.io/latest/docs/setup/additional-setup/config-profiles/</p> <p>There are a few preset profiles we can install:</p> <ul> <li>default</li> <li>demo</li> <li>minimal</li> <li>etc</li> </ul> <p></p> <p>I recommend to install <code>demo</code> profile, which comes with ingress/egress gateways, as well as grafana, kiali, jaegger (request tracing), and prometheus monitoring/metrics dashboards.</p> <pre><code># display the list of available profiles\nistioctl profile list\n\n# save config into yaml\nistioctl profile dump demo &gt; profile_demo_config.yaml\n</code></pre> <p>Output <pre><code>apiVersion: install.istio.io/v1alpha1\nkind: IstioOperator\nspec:\n  addonComponents:\n    grafana:\n      enabled: true\n      k8s:\n        replicaCount: 1\n    istiocoredns:\n      enabled: false\n    kiali:\n      enabled: true\n      k8s:\n        replicaCount: 1\n    prometheus:\n      enabled: true\n      k8s:\n        replicaCount: 1\n    tracing:\n      enabled: true\n  components:\n    base:\n      enabled: true\n    citadel:\n      enabled: false\n      k8s:\n        strategy:\n          rollingUpdate:\n            maxSurge: 100%\n            maxUnavailable: 25%\n    cni:\n      enabled: false\n    egressGateways:\n    - enabled: true\n      k8s:\n        resources:\n          requests:\n            cpu: 10m\n            memory: 40Mi\n      name: istio-egressgateway\n</code></pre></p> <pre><code># generate a k8s manifest for profile \"demo\" before installation\nistioctl manifest generate \\\n  --set profile=demo \\\n  --set values.gateways.istio-ingressgateway.sds.enabled=true \\\n  &gt; generated-manifest-demo.yaml\n</code></pre> <p>Install/update istio (won't work on v1.6)</p> <p>~~kubectl apply -f generated-manifest-demo.yaml~~ <pre><code># note: \"istioctl manifest apply\" works for both v1.5 and v1.6, but will be deprecated from v1.7 in favor of istioctl install\n&lt;!-- istioctl manifest apply \\\n  --set profile=demo \\\n  --set values.gateways.istio-ingressgateway.sds.enabled=true  --&gt;\n\n# use \"istioctl install\" instead\nistioctl install --set profile=demo\n</code></pre></p> <p>Output</p> show<p> <pre><code>\u2714 Istio core installed                                                                          \u2714 Istiod installed  \n\u2714 Ingress gateways installed\n\u2714 Egress gateways installed                                                                     \u2714 Addons installed                                                                              \u2714 Installation complete\n</code></pre> </p> <p>Analyze and detect potential issues with your Istio configuration <pre><code>istioctl analyze --all-namespaces\n\n# output\nWarn [IST0102] (Namespace default) The namespace is not enabled for Istio injection. Run 'kubectl label namespace default istio-injection=enabled' to enable it, or 'kubectl label namespace default istio-injection=disabled' to explicitly mark it as not needing injection\nWarn [IST0102] (Namespace kube-node-lease) The namespace is not enabled for Istio injection. Run 'kubectl label namespace kube-node-lease istio-injection=enabled' to enable it, or 'kubectl label namespace kube-node-lease istio-injection=disabled' to explicitly mark it as not needing injection\nError: Analyzers found issues when analyzing all namespaces.\nSee https://istio.io/docs/reference/config/analysis for more information about causes and resolutions.\n</code></pre></p> <p>Show objects created <pre><code>kubectl get pod,svc -n istio-system\n\n# output\nNAME                                        READY   STATUS    RESTARTS   AGE\npod/grafana-5cc7f86765-krwvf                1/1     Running   0          5m51s\npod/istio-egressgateway-5c8f9897f7-sfqg6    1/1     Running   0          29m\npod/istio-ingressgateway-65dd885d75-bbqtn   1/1     Running   0          29m\npod/istio-tracing-8584b4d7f9-whwjr          1/1     Running   0          5m39s\npod/istiod-7d6dff85dd-w5szx                 1/1     Running   0          29m\npod/kiali-696bb665-sngrt                    1/1     Running   0          5m43s\npod/prometheus-564768879c-w55nb             2/2     Running   0          5m39s\n\nNAME                                TYPE           CLUSTER-IP       EXTERNAL-IP                                                              PORT(S)                                                                                                                                      AGE\nservice/grafana                     ClusterIP      172.20.151.105   &lt;none&gt;                                                                   3000/TCP                                                                                                                                     5m50s\nservice/istio-egressgateway         ClusterIP      172.20.208.92    &lt;none&gt;                                                                   80/TCP,443/TCP,15443/TCP                                                                                                                     29m\nservice/istio-ingressgateway        LoadBalancer   172.20.170.225   aa7cfd0021476452ba8c3836365f2df3-478100139.us-east-1.elb.amazonaws.com   15020:31474/TCP,80:30046/TCP,443:31013/TCP,15029:31841/TCP,15030:31961/TCP,15031:30599/TCP,15032:30637/TCP,31400:31608/TCP,15443:32324/TCP   29m\nservice/istio-pilot                 ClusterIP      172.20.97.20     &lt;none&gt;                                                                   15010/TCP,15011/TCP,15012/TCP,8080/TCP,15014/TCP,443/TCP                                                                                     29m\nservice/istiod                      ClusterIP      172.20.236.155   &lt;none&gt;                                                                   15012/TCP,443/TCP                                                                                                                            29m\nservice/jaeger-agent                ClusterIP      None             &lt;none&gt;                                                                   5775/UDP,6831/UDP,6832/UDP                                                                                                                   5m35s\nservice/jaeger-collector            ClusterIP      172.20.177.164   &lt;none&gt;                                                                   14267/TCP,14268/TCP,14250/TCP                                                                                                                5m37s\nservice/jaeger-collector-headless   ClusterIP      None             &lt;none&gt;                                                                   14250/TCP                                                                                                                                    5m36s\nservice/jaeger-query                ClusterIP      172.20.116.249   &lt;none&gt;                                                                   16686/TCP                                                                                                                                    5m38s\nservice/kiali                       ClusterIP      172.20.253.248   &lt;none&gt;                                                                   20001/TCP                                                                                                                                    5m45s\nservice/prometheus                  ClusterIP      172.20.101.184   &lt;none&gt;                                                                   9090/TCP                                                                                                                                     5m41s\nservice/tracing                     ClusterIP      172.20.143.171   &lt;none&gt;                                                                   80/TCP                                                                                                                                       5m33s\nservice/zipkin                      ClusterIP      172.20.170.147   &lt;none&gt;                                                                   9411/TCP                                          \n</code></pre></p> <p>In cas you're using AWS as a cloud provider, you should notice that the service <code>istio-ingressgateway</code> in <code>istio-system</code> namespace created AWS ELB of type classic load balancer <pre><code>service/istio-ingressgateway        LoadBalancer   10.100.229.231   a5a1acc36239d46038f3dd828465c946-706040707.us-west-2.elb.amazonaws.com   15020:32676/TCP,80:32703/TCP,443:30964/TCP,31400:30057/TCP,15443:32059/TCP   15m\n</code></pre></p> <p>Using AWS console, check AWS ELB created by istio ingress gateway service:</p> <p></p> <p>Also notice a pod <code>istiod-7d6dff85dd-w5szx</code>. This is the pod that contains istio pilot (service discovery), Galley (config), sidecar injector, that is <code>istiod</code>.</p> <p>istiod unifies functionality that Pilot, Galley, Citadel and the sidecar injector previously performed, into a single binary</p>"},{"location":"mesh_installation/#enable-istio-sidecar-injection","title":"Enable Istio Sidecar Injection","text":"<p>Add a namespace label to instruct Istio to automatically inject Envoy sidecar proxies when you deploy your application later <pre><code># first describe default namespace\nkubectl describe ns default\n\n# output\nName:         default\nLabels:       &lt;none&gt;\nAnnotations:  &lt;none&gt;\nStatus:       Active\nNo resource quota.\nNo resource limits.\n\n# enable istio sidecar injection by adding a label\nkubectl label namespace default istio-injection=enabled\n\n# verify label is added\n# output\nName:         default\nLabels:       istio-injection=enabled\nAnnotations:  &lt;none&gt;\nStatus:       Active\nNo resource quota.\nNo resource limits.\n\n# to disable\nkubectl label namespace default istio-injection-\n</code></pre></p>"},{"location":"mesh_observability/","title":"Monitoring and Telemtry","text":"<p>When installing istio using vanilla flavour <code>demo</code> profile or the redhat istio service mesh 2.0 operator, it installed monitoring tools such as <code>grafana</code>, <code>prometheus</code>, <code>kiali</code>, <code>jaeger</code>. We will cover these a bit more in this section.</p> <pre><code># list pods\nkubectl get pod -n istio-system\n\n# output\nNAME                                    READY   STATUS    RESTARTS   AGE\ngrafana-74dc798895-5wwk8                1/1     Running   0          22m\nistio-egressgateway-7c6c6cd8b9-c87lz    1/1     Running   0          22m\nistio-ingressgateway-5d869f5bbf-bvpxs   1/1     Running   0          22m\nistio-tracing-8584b4d7f9-7wmsw          1/1     Running   0          22m\nistiod-648555b9b7-qgtg9                 1/1     Running   0          23m\nkiali-6f457f5964-9dhh9                  1/1     Running   0          22m\nprometheus-7fb8c98b68-h2rfp             2/2     Running   0          22m\n</code></pre>"},{"location":"mesh_observability/#check-grafana-dashboard","title":"Check Grafana dashboard","text":"<p>Istio vanilla flavour On k8s: <pre><code>istioctl dashboard grafana\n</code></pre></p> <p>Redhat Istio service mesh 2.0 On Openshift: <pre><code>oc dashboard grafana\n</code></pre></p>"},{"location":"mesh_observability/#grafana-dashboard-walkthrough","title":"Grafana Dashboard Walkthrough","text":"<p>Create kubernetes dashboard on grafana by: + icon &gt; type <code>3119</code> dashboard ID &gt; Select \u2018Prometheus\u2019 as the endpoint under prometheus data sources drop down.</p> <p></p> <p>In the web UI, you can see all the targets and metrics being monitored by grafana: </p>"},{"location":"mesh_observability/#practically-useful-grafana-community-dashboards","title":"Practically useful Grafana community dashboards","text":"<ul> <li>K8 Cluster Detail Dashboard</li> <li>K8s Cluster Summary</li> <li>Kubernetes cluster monitoring</li> </ul>"},{"location":"mesh_observability/#check-kiali-dashboard","title":"Check Kiali Dashboard","text":"<p>Istio vanilla flavour on K8s:</p> <pre><code>istioctl dashboard kiali\n</code></pre> <p>Redhat Istio service mesh 2.0 On Openshift: <pre><code>oc dashboard kiali\n</code></pre></p> <p>Username and password is <code>admin</code> by default.</p> <p></p> <p>Will walk through Kiali more in this section.</p>"},{"location":"oauth_jwt/","title":"Configuring OAuth Authentication for Edge Traffic","text":"<p>In this section, we go through these native authentication/authorization mechanisms, and explore a way to implement a full automated workflow based on OIDC. Keycloak is used as the authentication/authorization entity. All the code and more detailed READMEs for each approach are available in the corresponding subdirectories.</p> <p>This section assumes a running OCP 4 cluster (&gt;= 4.6) and cluster-admin user are available.</p> <p>For the sake of simplicity, it is better to delete and re-create the istio control plane and the AIDC application when trying the different approaches below.</p>"},{"location":"oauth_jwt/#requirements","title":"Requirements","text":"<ul> <li>Have an OCP 4.6 running cluster</li> <li>Have a user with cluster-admin role</li> <li>Have Service Mesh 2.0 installed</li> <li>Have a keycloak platform secured with non self-signed certificates</li> <li>if your keycloak is secured with self-signed certificates, you have to deploy keycloak on another physical server other than the one hosting the Openshift cluster</li> <li>Have the AIDC service mesh application deployed</li> </ul>"},{"location":"oauth_jwt/#approach-1-using-istio-native-mechanisms-for-jwt-based-authorization-used-for-dispatch-access-backend","title":"Approach 1: Using Istio native mechanisms for JWT-based authorization (used for dispatch access [Backend])","text":"<p>In this approach, access to the <code>AIDC</code> application is restricted using Istio-related CRD RequestAuthentication and AuthorizationPolicy deployed in the cluster. A user can access the application by providing a JWT token in its HTTP request (through the HTTP Header <code>Authorization</code>).</p> <p></p> <p>The workflow is as follows:</p> <ol> <li>the user authenticates to keycloak and get a JWT token (not shown in the above picture);</li> <li>the user performs an HTTP request to <code>https://&lt;dispatch-route&gt;/dispatchOC/domainOC/technical</code> and passes along this request the JWT token;</li> <li>the Istio ingress gateway (default one) forwards the request and the JWT token to the istio-proxy container of the dispatch pod;</li> <li>the istio-proxy container of the dispatch pod checks the validity of the JWT token depending on the <code>RequestAuthentication</code> and <code>AuthorizationPolicy</code> objects deployed beforehand;</li> <li>if the JWT token is valid, user accesses <code>/dispatchOC/domainOC/technical</code> - otherwise, an error message is returned to the user (code 404, message \"RBAC denied\" or others).</li> </ol>"},{"location":"oauth_jwt/#pros","title":"Pros:","text":"<ul> <li>the simplest approach (only 2 CR to be deployed)</li> <li>fine-grained authorization based on JWT token fields</li> </ul>"},{"location":"oauth_jwt/#cons","title":"Cons:","text":"<ul> <li>no OIDC workflow: the user must get a JWT token on its own, and pass it with the HTTP request on its own</li> <li>need to define <code>RequestAuthentication</code> and <code>AuthorizationPolicy</code> objects for each application to protect inside the service mesh</li> </ul>"},{"location":"oauth_jwt/#approach-2-injecting-oauth2-proxy-container-inside-the-istio-ingress-gateway-to-implement-an-oidc-workflow-used-for-studio-access-frontend","title":"Approach 2: Injecting oauth2-proxy container inside the Istio ingress gateway to implement an OIDC workflow (used for studio access [Frontend])","text":"<p>In this approach, access to the <code>AIDC</code> application is restricted by injecting an oauth2-proxy sidecar container to the Istio ingress gateway. The oauth2-proxy will enforce user authentication with Keycloak before forwarding any request to the istio-proxy (the default container of the Istio ingress gateway). In this approach, the OIDC workflow between the user, oauth2-proxy and Keycloak is perfomed automatically.</p> <p></p> <p>The workflow is as follows:</p> <ol> <li>the user performs an unauthenticated HTTP request to <code>https://&lt;studio-route&gt;</code>;</li> <li>the oauth2-proxy inside the Istio ingress gateway pod initiates the OIDC workflow to authenticate the user; user authenticates to keycloak (not shown on the picture);</li> <li>the user performs an authenticated HTTP request to <code>https://&lt;studio-route&gt;</code>; the authentication is checked by the oauth2-proxy using HTTP cookies;</li> <li>the oauth2-proxy forwards locally (same pod) the request to the istio-proxy container of the Istio ingress gateway, which in turn forwards the request to the istio-proxy container of the studio pod;</li> <li>user accesses <code>&lt;studio-route&gt;</code>.</li> </ol>"},{"location":"oauth_jwt/#pros_1","title":"Pros:","text":"<ul> <li>authentication enforced at the ingress gateway level (no need to define <code>RequestAuthentication</code> and <code>AuthorizationPolicy</code> objects for each application)</li> <li>automated OIDC workflow to authenticate the user</li> </ul>"},{"location":"oauth_jwt/#cons_1","title":"Cons:","text":"<ul> <li>coarse-grained authorization (authenticated == authorized)</li> <li>complex setup (involve patches)</li> </ul>"},{"location":"oauth_jwt/#approach-3-combining-jwt-based-authorization-and-oidc-workflow-best-of-both-approaches","title":"Approach 3: Combining JWT-based authorization and OIDC workflow (Best of both approaches)","text":"<p>This approach combines the use of <code>RequestAuthentication</code> and <code>AuthorizationPolicy</code> objects as done for approach 1, and the injection of the oauth2-proxy container as done in the approach 2. In this approach, the oauth2-proxy container extracts the JWT token from the authentication cookie, and forwards it to the istio-proxy container alongside the HTTP request (using the <code>X-Forwarded-Access-Token</code> HTTP header). As a result, an automated OIDC workflow to authenticate the user is performed, and can be, if needed, combined to a fine-grained authorization based on JWT token fields (e.g. simple auth for 'non-secure' apps, auth + JWT field for more secure apps).</p> <p></p> <p>The workflow is as follows:</p> <ol> <li>the user performs an unauthenticated HTTP request to <code>https://&lt;studio-route&gt;</code>;</li> <li>the oauth2-proxy inside the Istio ingress gateway pod initiates the OIDC workflow to authenticate the user; user authenticates to keycloak (not shown on the picture);</li> <li>the user performs an authenticated HTTP request to <code>https://&lt;studio-route&gt;</code>; the authentication is checked by the oauth2-proxy using HTTP cookies;</li> <li>the oauth2-proxy extracts the JWT token from the authentication cookie and forwards it locally (same pod) alongside the HTTP request to the istio-proxy container of the Istio ingress gateway;</li> <li>the istio-proxy container of the Istio ingress gateway forwards the request and the JWT token to the istio-proxy container of the studio pod;</li> <li>the istio-proxy container of the studio pod checks the validity of the JWT token depending on the <code>RequestAuthentication</code> and <code>AuthorizationPolicy</code> objects deployed beforehand;</li> <li>if the JWT token is valid, user accesses <code>&lt;studio-route&gt;</code> - otherwise, an error message is returned to the user (code 404, message \"RBAC denied\" or others).</li> </ol>"},{"location":"oauth_jwt/#pros_2","title":"Pros:","text":"<ul> <li>authentication enforced at the ingress gateway level</li> <li>automated OIDC workflow to authenticate the user</li> <li>if needed, fine-grained authorization based on JWT token fields</li> </ul>"},{"location":"oauth_jwt/#cons_2","title":"Cons:","text":"<ul> <li>complex setup (currently involves deployment / service / route patches)</li> </ul> <p>Usefull information:</p> <p>The request authentication is only making sure that when a JWT token is provided, it has to be a valid one. If there is no token, it will just pass through the request.</p> <p>You could add more gateways to this service mesh deployment in case you need to handle unauthenticated traffic or traffic using a different authentication method.</p> <p>Once the token is created via the authentication workflow, you can configure the ingress gateway to verify it. Additionally, you can configure all of the services in the mesh to re-verify the token, increasing your security. In order for this to work, your services need to forward the token at every step.</p> <p>If you provide a token in the authorization header, its implicitly default location, Istio validates the token using the public key set, and rejects requests if the bearer token is invalid. However, requests without tokens are accepted.</p>"},{"location":"oauth_jwt/#reference","title":"Reference","text":"<p>Istio Authorization architecture</p>"},{"location":"styleref/","title":"Homepage","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"styleref/#code-annotation-examples","title":"Code Annotation Examples","text":""},{"location":"styleref/#codeblockss","title":"Codeblockss","text":"<p>Some <code>code</code> goes here.</p>"},{"location":"styleref/#plain-codeblock","title":"Plain codeblock","text":"<p>A plain codeblock:</p> <pre><code>Some code here\ndef myfunction()\n// some comment\n</code></pre>"},{"location":"styleref/#code-for-a-specific-language","title":"Code for a specific language","text":"<p>Some more code with the <code>py</code> at the start:</p> <pre><code>import tensorflow as tf\ndef whatever()\n</code></pre>"},{"location":"styleref/#with-a-title","title":"With a title","text":"bubble_sort.py<pre><code>def bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n</code></pre>"},{"location":"styleref/#with-line-numbers","title":"With line numbers","text":"<pre><code>def bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n</code></pre>"},{"location":"styleref/#highlighting-lines","title":"Highlighting lines","text":"<pre><code>def bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n</code></pre>"},{"location":"styleref/#icons-and-emojs","title":"Icons and Emojs","text":"<p>:smile: </p> <p>:fontawesome-regular-face-laugh-wink:</p> <p>:fontawesome-brands-twitter:{ .twitter }</p> <p>:octicons-heart-fill-24:{ .heart }</p>"},{"location":"styleref/#references","title":"References","text":""},{"location":"styleref/#references_1","title":"References","text":"<ul> <li>Service mesh patterns repository</li> <li>https://github.com/cloudfirst-dev/istio-egress-traffic-control</li> <li>Hints about how to debug istio</li> <li>oauth2-proxy repository</li> <li>oauth2-proxy integration with RHSSO</li> <li>Istio RequestAuthentication</li> <li>Istio AuthorizationPolicy and conditions</li> </ul>"},{"location":"traffic_management/","title":"Traffic Management","text":"<p>Remember in the introduction section, we talked about Istio Service Mesh Architecture:</p> <ul> <li>Data Plane (Envoy proxy)</li> <li>Control Plane (Istiod)</li> </ul> <p>All traffic that your mesh services send and receive (data plane traffic) is proxied through Envoy, making it easy to direct and control traffic around your mesh without making any changes to your services.</p> <p></p> <p>To recap what Data Plane's Envoy Proxy is capable of:</p> <ul> <li>Envoy Proxy: a high-performance proxy developed in C++ to mediate all inbound and outbound traffic for all services in the service mesh. Envoy proxies are the only Istio components that interact with data plane traffic.</li> <li>Traffic control<ul> <li>a different load balancing policy to traffic for a particular subset of service instances</li> <li>Staged rollouts with %-based traffic split</li> <li>HTTP/2 and gRPC proxies</li> </ul> </li> <li>Network resiliency<ul> <li>Timeouts</li> <li>Retries</li> <li>Circuit breakers</li> <li>Fault injection</li> </ul> </li> <li>Security and Authentication<ul> <li>rate limiting</li> <li>TLS termination</li> </ul> </li> <li>Istio Resources that enable above features<ul> <li>Virtual services   # &lt; ----- what is this?<ul> <li>without VirtualService, Envoy distributes traffic using round-robin load balancing between all service instances. This is what K8s service's L4 load balancing can do for you.</li> </ul> </li> <li>Destination rules</li> <li>Gateways</li> <li>Service entries<ul> <li>if the destination\u2019s host is outside Istio service mesh (e.g. AWS RDS endpoint), non-mesh service needs to be added using a service entry</li> </ul> </li> <li>Sidecars</li> </ul> </li> </ul> <p>In my personal experience, I didn't implement all of this traffic management features, only the most important ones, obviously because of the project deadline. </p> <p>Here are the prioritized traffic management design implemented:</p>"},{"location":"traffic_management/#timeout-configuraiton-for-resilience-testing-using-virtualservice","title":"Timeout configuraiton for Resilience Testing using VirtualService","text":"<p>A timeout is the amount of time that an Envoy proxy should wait for replies from a given service, ensuring that services don\u2019t hang around waiting for replies indefinitely and that calls succeed or fail within a predictable timeframe. The default timeout for HTTP requests is 15 seconds, which means that if the service doesn\u2019t respond within 15 seconds, the call fails.</p> <p>Istio lets you easily adjust timeouts dynamically on a per-service basis using virtual services without having to edit your service code.</p> <p>For example, let's configure 3 seconds timeout for the dispatch virtual service:</p> <pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: aidc-dispatch-vs\nspec:\n  hosts: # destinations that these routing rules apply to. VirtualService must be bound to the gateway and must have one or more hosts that match the hosts specified in a server\n  - \"*\"\n  gateways: # names of gateways and sidecars that should apply these routes\n  - dispatch-gateway # Don't ONLY USE this gateway as \"reviews\" k8s service is used internally by productpage service, so this VS rule should be applied to Envoy sidecar proxy inside reviews pod, not edge proxy in gateway pod.\n  http: # L7 load balancing by http path and host, just like K8s ingress resource\n  - timeout: 3s # &lt;--- default timeout for HTTP requests is 15 seconds, which means that if the service doesn\u2019t respond within 15 seconds, the call fails\n    route:\n    - destination:\n        host: dispatch-svc\n        port:\n          number: 444\n</code></pre> <p>Apply <pre><code>oc apply -f virtualservice-dispatch.yaml\n</code></pre></p>"},{"location":"traffic_management/#configure-retry-for-resilience-testing-using-virtualservice","title":"Configure Retry for Resilience Testing using VirtualService","text":"<p>The following example configures a maximum of 3 retries to connect to dispatch service subset after an initial call failure, each with a 3 second timeout.</p> virtualservice-dispatch.yaml<pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata: \n  name: aidc-dispatch-vs\n  namespace: keycloak-servicemesh\nspec:\n  hosts:\n  - \"*\"\n  gateways:\n  - dispatch-gateway\n  http:\n  - timeout: 3s\n  - retries:\n      attempts: 3 # default 1. The number of retries for a given request. The interval between retries will be determined automatically (25ms+). Actual number of retries attempted depends on the request timeout\n      perTryTimeout: 3s\n      retryOn: 5xx,gateway-error,reset,connect-failure,refused-stream,retriable-4xx\n  - name: \"dispatch-route\"\n    route:\n    - destination:\n        host: dispatch-svc\n        port:\n          number: 444\n</code></pre>"},{"location":"traffic_management/#enable-rate-limiting-by-configuring-connection-pool-sizes-in-destinationrule","title":"Enable Rate Limiting by Configuring Connection Pool sizes in DestinationRule","text":"<p>Connection pool settings can be applied at the TCP level as well as at HTTP level.</p> <p>For example, the following yaml sets a limit of 2 concurrent connections to dispatch service with a connect timeout of 30ms.</p> destination_rules_dispatch_circuit_breaker.yaml<pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: DestinationRule\nmetadata:\n  name: dispatch\nspec:\n  host: dispatch # name of a service from the service registry\n  trafficPolicy: # service-level routing policy\n      connectionPool: # &lt;------  ref: https://istio.io/latest/docs/reference/config/networking/destination-rule/#ConnectionPoolSettings\n        http:\n          http2MaxRequests: 1 # limit of 50 concurrent HTTP2 requests\n          maxRequestsPerConnection: 1\n        tcp:\n          maxConnections: 2 # connection pool size of 2 HTTP1 connections\n          connectTimeout: 30ms\n          tcpKeepalive:\n            time: 7200s\n            interval: 75s\n</code></pre>"},{"location":"traffic_management/#enable-circuit-breaker-by-configuring-outlierdetection-in-destinationrule","title":"Enable Circuit Breaker by Configuring OutlierDetection in DestinationRule","text":"<p>Refs: - https://istio.io/latest/docs/tasks/traffic-management/circuit-breaking/ - https://istio.io/latest/docs/concepts/traffic-management/#circuit-breakers</p> <ul> <li>HTTP services<ul> <li>hosts that continually return 5xx errors for API calls are ejected from the pool for a pre-defined period of time</li> </ul> </li> <li>TCP services<ul> <li>connection timeouts or connection failures to a given host counts as an error when measuring the consecutive errors metric</li> </ul> </li> </ul> <p>In this yaml configures dispatch upstream hosts to be scanned every 1 second so that any host that fails 1 consecutive time with a 502, 503, or 504 error code will be ejected for 3 minutes.</p> destination_rules_dispatch_circuit_breaker.yaml<pre><code>apiVersion: networking.istio.io/v1alpha3\nkind: DestinationRule\nmetadata:\n  name: dispatch\nspec:\n  host: dispatch # name of a service from the service registry\n  trafficPolicy: # service-level routing policy\n      connectionPool: # ref: https://istio.io/latest/docs/reference/config/networking/destination-rule/#ConnectionPoolSettings\n        http:\n          http2MaxRequests: 1 # limit of 1 concurrent HTTP2 requests\n          maxRequestsPerConnection: 1\n        tcp:\n          maxConnections: 2 # connection pool size of 2 HTTP1 connections\n          connectTimeout: 30ms\n          tcpKeepalive:\n            time: 7200s\n            interval: 75s\n      outlierDetection: # &lt;-----  ref: https://istio.io/latest/docs/reference/config/networking/destination-rule/#OutlierDetection\n        consecutiveErrors: 1\n        interval: 1s # scans every 1s\n        baseEjectionTime: 3m \n</code></pre> <p>Apply  <pre><code>oc apply -f destination_rules_dispatch_circuit_breaker.yaml\n</code></pre></p> <p>You will see Circuit Breaker icon on <code>productpage</code> workload on Kiali: </p>"},{"location":"traffic_management/#how-to-test-circuit-breaker","title":"How to Test Circuit Breaker","text":"<p>While the following example is for kubernetes, the sames goes for Openshift.</p> <p>Create a fortio pod <pre><code># create a pod\nkubectl apply -f ../istio-1.6.7/samples/httpbin/sample-client/fortio-deploy.yaml\n\n# test curl the bookinfo productpage URL\nFORTIO_POD=$(kubectl get pods -lapp=fortio -o 'jsonpath={.items[0].metadata.name}')\nBOOKINFO_URL=$(echo $(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')/productpage)\n\nkubectl exec -it \"$FORTIO_POD\" -c fortio -- /usr/bin/fortio load -curl \"$BOOKINFO_URL\"\n</code></pre></p> <p>Now make tons of request <pre><code># Call the service with two concurrent connections (-c 2) and send 20 requests (-n 20)\nkubectl exec -it \"$FORTIO_POD\" -c fortio -- /usr/bin/fortio load -c 2 -qps 0 -n 20 -loglevel Warning \"$BOOKINFO_URL\"\n\n# output\n15:49:54 I logger.go:114&gt; Log level is now 3 Warning (was 2 Info)\nFortio 1.6.5 running at 0 queries per second, 2-&gt;2 procs, for 20 calls: a5a1acc36239d46038f3dd828465c946-706040707.us-west-2.elb.amazonaws.com/productpage\n15:49:54 W http_client.go:143&gt; Assuming http:// on missing scheme for 'a5a1acc36239d46038f3dd828465c946-706040707.us-west-2.elb.amazonaws.com/productpage'\nStarting at max qps with 2 thread(s) [gomax 2] for exactly 20 calls (10 per thread + 0)\nEnded after 624.901397ms : 20 calls. qps=32.005\nAggregated Function Time : count 20 avg 0.060465896 +/- 0.01994 min 0.025406513 max 0.086700868 sum 1.20931791\n# range, mid point, percentile, count\n&gt;= 0.0254065 &lt;= 0.03 , 0.0277033 , 15.00, 3\n&gt; 0.03 &lt;= 0.035 , 0.0325 , 25.00, 2\n&gt; 0.05 &lt;= 0.06 , 0.055 , 30.00, 1\n&gt; 0.06 &lt;= 0.07 , 0.065 , 65.00, 7\n&gt; 0.07 &lt;= 0.08 , 0.075 , 90.00, 5\n&gt; 0.08 &lt;= 0.0867009 , 0.0833504 , 100.00, 2\n# target 50% 0.035\n# target 75% 0.07\n# target 90% 0.08\n# target 99% 0.0927821\n# target 99.9% 0.0934081\nSockets used: 11 (for perfect keepalive, would be 2)\nJitter: false\nCode 200 : 10 (50.0 %)\nCode 503 : 10 (50.0 %) # &lt;------- half returning 5xx\nResponse Header Sizes : count 20 avg 84 +/- 84 min 0 max 168 sum 1680\nResponse Body/Total Sizes : count 20 avg 2811.3 +/- 2536 min 275 max 5351 sum 56226\nAll done 20 calls (plus 0 warmup) 38.917 ms avg, 31.2 qps\n</code></pre></p> <p>These were trapped by circuit breaking <pre><code>Code 200 : 10 (50.0 %)\nCode 503 : 10 (50.0 %) # &lt;------- half returning 5xx\n</code></pre></p>"},{"location":"why_istio/","title":"1. Why Istio","text":"<p>Ref: https://istio.io/blog/2020/tradewinds-2020/</p> <p>Service mesh requirements can be thought of as a typical API gateway functionality, but instead of having just one API gateway, consider each sidecar Envoy proxies acting as API gateway:</p>"},{"location":"why_istio/#benefits","title":"Benefits:","text":""},{"location":"why_istio/#traffic-management","title":"Traffic Management","text":"<ul> <li>Control Ingress Traffic using Gateway, VirtualService, DestinationRules  </li> </ul>"},{"location":"why_istio/#load-balancing","title":"Load balancing","text":""},{"location":"why_istio/#service-entry","title":"Service Entry","text":"<p>Provides the ability to manually define endpoints that cannot be auto-discovered and may represent destinations outside of the mesh (location: MESH_EXTERNAL).</p>"},{"location":"why_istio/#request-routing","title":"Request Routing","text":"<p>Fine-grained control of traffic behavior with rich routing rules, retries, failovers, and fault injection - TLS termination </p>"},{"location":"why_istio/#canary-rollouts","title":"Canary rollouts","text":""},{"location":"why_istio/#identityheader-based-routing","title":"Identity/header based routing","text":""},{"location":"why_istio/#failure-recovery-delay-abort-retries-timeout","title":"Failure recovery (delay, abort, retries, timeout)","text":""},{"location":"why_istio/#mirror-live-traffic","title":"Mirror live traffic","text":""},{"location":"why_istio/#rate-limiting","title":"Rate limiting","text":""},{"location":"why_istio/#circuit-breaker","title":"Circuit breaker","text":""},{"location":"why_istio/#control-egress-traffic","title":"Control egress traffic","text":""},{"location":"why_istio/#security","title":"Security","text":"<ul> <li>transparently secure traffic behind the firewall (Auto mutual TLS among backend services, which doubles the latency at max or max 10ms, also explained in Istio best practice blog)  </li> </ul>"},{"location":"why_istio/#end-to-end-authentication-and-authorization-using-jwt","title":"End-to-end authentication and authorization using JWT","text":""},{"location":"why_istio/#observability","title":"Observability","text":"<ul> <li>Debug the latency in the overall architecture </li> <li>Automatic metrics, logs, and traces for all traffic within a cluster, including cluster ingress and egress     </li> <li>Raw telemetry data are sent from envoy proxy to Mixer, which Mixer processes into metrics, traces, and other telemetry</li> <li> <p>New in istio 1.5 and 1.6</p> <ul> <li>Reduced installation and configuration complexity by moving control plane components into a single component: Istiod. This binary includes the features of Pilot, Citadel, Galley, and the sidecar injector</li> <li>High performant (Istio Performance Benchmarking and script, egress gateway performance testing)       </li> </ul> </li> <li> <p>Refs:</p> <ul> <li>Istio with Kubernetes on AWS</li> <li>Kiali: Istio dashboard</li> <li>Istio sidecar injection failing with error - MountVolume.SetUp failed for volume \"istiod-ca-cert\" : configmap \"istio-ca-root-cert\" not found #22463</li> <li>Failed to get secret \"istio-ca-secret\" thus istiod pod's readiness probe fails on EKS #24009</li> </ul> </li> </ul>"}]}